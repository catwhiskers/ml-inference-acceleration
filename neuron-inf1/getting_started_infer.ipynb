{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial: Getting started with torch-neuron (resnet-50 tutorial - infer steps in code)\n",
    "\n",
    "**NOTE:** This notebook content represents the compilation parts of the [getting started tutorial](./getting_started.md) - it is not intended to used without reference to the tutorial. This is why we start at step 5 below :)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Run inference\n",
    "\n",
    "In this step we run inference on Inf1 instances using the model compiled in Step 3 of [getting started compile](getting_started_compile.ipnb), which should have been copied to this machine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting torch-neuron~=1.7.0\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/torch-neuron/torch_neuron-1.7.1.1.2.16.0-py3-none-linux_x86_64.whl (8.3 MB)\n",
      "Collecting torchvision~=0.8.2\n",
      "  Using cached torchvision-0.8.2-cp36-cp36m-manylinux1_x86_64.whl (12.8 MB)\n",
      "Collecting neuron-cc\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/neuron-cc/neuron_cc-1.2.7.0%2Beaf2e01fb-cp36-cp36m-linux_x86_64.whl (59.7 MB)\n",
      "Collecting torch~=1.7.1\n",
      "  Using cached torch-1.7.1-cp36-cp36m-manylinux1_x86_64.whl (776.8 MB)\n",
      "Collecting tensorflow~=1.15.0\n",
      "  Using cached tensorflow-1.15.5-cp36-cp36m-manylinux2010_x86_64.whl (110.5 MB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting pillow\n",
      "  Using cached Pillow-8.2.0-cp36-cp36m-manylinux1_x86_64.whl (3.0 MB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.3.4-cp36-cp36m-manylinux1_x86_64.whl (11.5 MB)\n",
      "Collecting pycocotools\n",
      "  Using cached pycocotools-2.0.2-cp36-cp36m-linux_x86_64.whl\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting keras-preprocessing>=1.0.5\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting six>=1.10.0\n",
      "  Using cached six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting numpy<1.19.0,>=1.16.0\n",
      "  Using cached numpy-1.18.5-cp36-cp36m-manylinux1_x86_64.whl (20.1 MB)\n",
      "Collecting protobuf>=3.6.1\n",
      "  Using cached protobuf-3.15.8-cp36-cp36m-manylinux1_x86_64.whl (1.0 MB)\n",
      "Collecting wheel>=0.26\n",
      "  Using cached wheel-0.36.2-py2.py3-none-any.whl (35 kB)\n",
      "Collecting tensorflow-estimator==1.15.1\n",
      "  Using cached tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting wrapt>=1.11.1\n",
      "  Using cached wrapt-1.12.1-cp36-cp36m-linux_x86_64.whl\n",
      "Collecting h5py<=2.10.0\n",
      "  Using cached h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9 MB)\n",
      "Collecting astor>=0.6.0\n",
      "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting tensorboard<1.16.0,>=1.15.0\n",
      "  Using cached tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n",
      "Collecting grpcio>=1.8.6\n",
      "  Using cached grpcio-1.37.0-cp36-cp36m-manylinux2014_x86_64.whl (4.2 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting gast==0.2.2\n",
      "  Using cached gast-0.2.2-py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Using cached Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "Collecting absl-py>=0.7.0\n",
      "  Using cached absl_py-0.12.0-py3-none-any.whl (129 kB)\n",
      "Collecting dataclasses\n",
      "  Using cached dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Collecting typing-extensions\n",
      "  Using cached typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting setuptools\n",
      "  Downloading setuptools-56.0.0-py3-none-any.whl (784 kB)\n",
      "\u001b[K     |████████████████████████████████| 784 kB 32.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting importlib-metadata\n",
      "  Using cached importlib_metadata-3.10.0-py3-none-any.whl (14 kB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
      "  Using cached pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "Collecting python-dateutil>=2.1\n",
      "  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting dmlc-tvm==1.2.6.0\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/dmlc-tvm/dmlc_tvm-1.2.6.0%2B0-cp36-cp36m-linux_x86_64.whl (73.1 MB)\n",
      "Collecting islpy==2018.2\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/islpy/islpy-2018.2%2Baws2018.x.748.0.bld0-cp36-cp36m-linux_x86_64.whl (1.6 MB)\n",
      "Collecting numpy<1.19.0,>=1.16.0\n",
      "  Using cached numpy-1.18.4-cp36-cp36m-manylinux1_x86_64.whl (20.2 MB)\n",
      "Collecting networkx<=2.4\n",
      "  Using cached networkx-2.4-py3-none-any.whl (1.6 MB)\n",
      "Collecting dmlc-topi==1.2.6.0\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/dmlc-topi/dmlc_topi-1.2.6.0%2B0-py3-none-any.whl (1.5 MB)\n",
      "Collecting inferentia-hwm==1.2.6.0\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/inferentia-hwm/inferentia_hwm-1.2.6.0%2B0-cp36-cp36m-linux_x86_64.whl (49 kB)\n",
      "Collecting scipy<=1.4.1\n",
      "  Using cached scipy-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (26.1 MB)\n",
      "Collecting dmlc-nnvm==1.2.6.0\n",
      "  Using cached https://pip.repos.neuron.amazonaws.com/dmlc-nnvm/dmlc_nnvm-1.2.6.0%2B0-py3-none-any.whl (14.8 MB)\n",
      "Collecting decorator\n",
      "  Using cached decorator-5.0.6-py3-none-any.whl (8.8 kB)\n",
      "Collecting attrs\n",
      "  Using cached attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
      "Collecting cffi>=1.1.0\n",
      "  Using cached cffi-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (401 kB)\n",
      "Collecting pycparser\n",
      "  Using cached pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting cython>=0.27.3\n",
      "  Using cached Cython-0.29.22-cp36-cp36m-manylinux1_x86_64.whl (2.0 MB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
      "Installing collected packages: zipp, typing-extensions, six, pycparser, numpy, importlib-metadata, wheel, werkzeug, setuptools, python-dateutil, pyparsing, protobuf, pillow, markdown, kiwisolver, inferentia-hwm, h5py, grpcio, decorator, dataclasses, cycler, cffi, attrs, absl-py, wrapt, urllib3, torch, termcolor, tensorflow-estimator, tensorboard, scipy, opt-einsum, networkx, matplotlib, keras-preprocessing, keras-applications, islpy, idna, google-pasta, gast, dmlc-tvm, dmlc-topi, dmlc-nnvm, cython, chardet, certifi, astor, torchvision, torch-neuron, tensorflow, requests, pycocotools, neuron-cc\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.4.1\n",
      "    Uninstalling zipp-3.4.1:\n",
      "      Successfully uninstalled zipp-3.4.1\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.3\n",
      "    Uninstalling typing-extensions-3.7.4.3:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.3\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.15.0\n",
      "    Uninstalling six-1.15.0:\n",
      "      Successfully uninstalled six-1.15.0\n",
      "  Attempting uninstall: pycparser\n",
      "    Found existing installation: pycparser 2.20\n",
      "    Uninstalling pycparser-2.20:\n",
      "      Successfully uninstalled pycparser-2.20\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.4\n",
      "    Uninstalling numpy-1.18.4:\n",
      "      Successfully uninstalled numpy-1.18.4\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.0\n",
      "    Uninstalling importlib-metadata-3.10.0:\n",
      "      Successfully uninstalled importlib-metadata-3.10.0\n",
      "  Attempting uninstall: wheel\n",
      "    Found existing installation: wheel 0.36.2\n",
      "    Uninstalling wheel-0.36.2:\n",
      "      Successfully uninstalled wheel-0.36.2\n",
      "  Attempting uninstall: werkzeug\n",
      "    Found existing installation: Werkzeug 1.0.1\n",
      "    Uninstalling Werkzeug-1.0.1:\n",
      "      Successfully uninstalled Werkzeug-1.0.1\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 54.2.0\n",
      "    Uninstalling setuptools-54.2.0:\n",
      "      Successfully uninstalled setuptools-54.2.0\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 2.4.7\n",
      "    Uninstalling pyparsing-2.4.7:\n",
      "      Successfully uninstalled pyparsing-2.4.7\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.15.8\n",
      "    Uninstalling protobuf-3.15.8:\n",
      "      Successfully uninstalled protobuf-3.15.8\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: Pillow 8.2.0\n",
      "    Uninstalling Pillow-8.2.0:\n",
      "      Successfully uninstalled Pillow-8.2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: markdown\n",
      "    Found existing installation: Markdown 3.3.4\n",
      "    Uninstalling Markdown-3.3.4:\n",
      "      Successfully uninstalled Markdown-3.3.4\n",
      "  Attempting uninstall: kiwisolver\n",
      "    Found existing installation: kiwisolver 1.3.1\n",
      "    Uninstalling kiwisolver-1.3.1:\n",
      "      Successfully uninstalled kiwisolver-1.3.1\n",
      "  Attempting uninstall: inferentia-hwm\n",
      "    Found existing installation: inferentia-hwm 1.2.6.0+0\n",
      "    Uninstalling inferentia-hwm-1.2.6.0+0:\n",
      "      Successfully uninstalled inferentia-hwm-1.2.6.0+0\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.37.0\n",
      "    Uninstalling grpcio-1.37.0:\n",
      "      Successfully uninstalled grpcio-1.37.0\n",
      "  Attempting uninstall: decorator\n",
      "    Found existing installation: decorator 5.0.6\n",
      "    Uninstalling decorator-5.0.6:\n",
      "      Successfully uninstalled decorator-5.0.6\n",
      "  Attempting uninstall: dataclasses\n",
      "    Found existing installation: dataclasses 0.8\n",
      "    Uninstalling dataclasses-0.8:\n",
      "      Successfully uninstalled dataclasses-0.8\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.10.0\n",
      "    Uninstalling cycler-0.10.0:\n",
      "      Successfully uninstalled cycler-0.10.0\n",
      "  Attempting uninstall: cffi\n",
      "    Found existing installation: cffi 1.14.5\n",
      "    Uninstalling cffi-1.14.5:\n",
      "      Successfully uninstalled cffi-1.14.5\n",
      "  Attempting uninstall: attrs\n",
      "    Found existing installation: attrs 20.3.0\n",
      "    Uninstalling attrs-20.3.0:\n",
      "      Successfully uninstalled attrs-20.3.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.12.0\n",
      "    Uninstalling absl-py-0.12.0:\n",
      "      Successfully uninstalled absl-py-0.12.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.12.1\n",
      "    Uninstalling wrapt-1.12.1:\n",
      "      Successfully uninstalled wrapt-1.12.1\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 1.26.4\n",
      "    Uninstalling urllib3-1.26.4:\n",
      "      Successfully uninstalled urllib3-1.26.4\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.7.1\n",
      "    Uninstalling torch-1.7.1:\n",
      "      Successfully uninstalled torch-1.7.1\n",
      "  Attempting uninstall: termcolor\n",
      "    Found existing installation: termcolor 1.1.0\n",
      "\u001b[31mERROR: Cannot uninstall 'termcolor'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torch-neuron~=1.7.0 torchvision~=0.8.2 neuron-cc torch~=1.7.1 tensorflow~=1.15.0 requests pillow matplotlib pycocotools --force \\\n",
    "    --extra-index-url=https://pip.repos.neuron.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/aws/neuron/bin/neuron-cli reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "torchvision.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 labels:\n",
      " ['tiger', 'lynx', 'tiger_cat', 'Egyptian_cat', 'tabby']\n",
      "Completed 100 operations in 0.36 seconds => 280.0 images / second\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch_neuron\n",
    "import json\n",
    "import numpy as np\n",
    "from urllib import request\n",
    "from torchvision import models, transforms, datasets\n",
    "from time import time\n",
    "\n",
    "## Create an image directory containing a small kitten\n",
    "os.makedirs(\"./torch_neuron_test/images\", exist_ok=True)\n",
    "request.urlretrieve(\"https://raw.githubusercontent.com/awslabs/mxnet-model-server/master/docs/images/kitten_small.jpg\",\n",
    " \"./torch_neuron_test/images/kitten_small.jpg\")\n",
    "\n",
    "## Fetch labels to output the top classifications\n",
    "request.urlretrieve(\"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\",\"imagenet_class_index.json\")\n",
    "idx2label = []\n",
    "\n",
    "with open(\"imagenet_class_index.json\", \"r\") as read_file:\n",
    " class_idx = json.load(read_file)\n",
    " idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]\n",
    "\n",
    "## Import a sample image and normalize it into a tensor\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225])\n",
    "\n",
    "eval_dataset = datasets.ImageFolder(\n",
    "    os.path.dirname(\"./torch_neuron_test/\"),\n",
    "    transforms.Compose([\n",
    "        transforms.Resize([224, 224]),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    ")\n",
    "image, _ = eval_dataset[0]\n",
    "image = torch.tensor(image.numpy()[np.newaxis, ...])\n",
    "\n",
    "## Load model\n",
    "model_neuron = torch.jit.load( 'resnet50_neuron.pt' )\n",
    "\n",
    "## Since the first inference also load the model let's exclude it \n",
    "## from timing\n",
    "results = model_neuron( image )\n",
    "\n",
    "## Predict for 100 loops\n",
    "start = time()\n",
    "\n",
    "loops = 100\n",
    "for _ in range(loops):\n",
    "    results = model_neuron( image )\n",
    "elapsed_time = time() - start\n",
    "images_sec = loops / float(elapsed_time)\n",
    "\n",
    "# Get the top 5 results\n",
    "top5_idx = results[0].sort()[1][-5:]\n",
    "\n",
    "# Lookup and print the top 5 labels\n",
    "top5_labels = [idx2label[idx] for idx in top5_idx]\n",
    "\n",
    "print(\"Top 5 labels:\\n {}\".format(top5_labels) )\n",
    "print(\"Completed {} operations in {} seconds => {} images / second\".format(loops, round(elapsed_time,2), round(images_sec,0) ) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run on parallel neuron cores\n",
    "\n",
    "To full leverage the inferentia hardware we want to use all the cores.  On an inf1.xlarge or inf1.2xlarge we need to use 4. Here we use the futures library to create a simple class that runs four parallel inference threads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent import futures\n",
    "import torch\n",
    "import torch.neuron\n",
    "import os\n",
    "\n",
    "class NeuronSimpleDataParallel():\n",
    "\n",
    "    def __init__(self, model_file, num_neuron_cores, batch_size=1):\n",
    "        # Construct a list of models\n",
    "        self.num_neuron_cores = num_neuron_cores\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        class SimpleWrapper():\n",
    "\n",
    "            def __init__(self, model):\n",
    "                self.model = model\n",
    "\n",
    "            def eval(self):\n",
    "                self.model.eval()\n",
    "\n",
    "            def train(self):\n",
    "                self.model.train()\n",
    "\n",
    "            def __call__(self, *args):\n",
    "                results = self.model(*args)\n",
    "\n",
    "                # Make the output iterable - if it is not already a tuple or list\n",
    "                if not isinstance(results, tuple) or isinstance(results, list):\n",
    "                    results = [results]\n",
    "\n",
    "                return results\n",
    "\n",
    "        self.models = [SimpleWrapper(torch.jit.load(model_file))\n",
    "                       for i in range(num_neuron_cores)]\n",
    "\n",
    "        ## Important - please read:\n",
    "        ##     https://github.com/aws/aws-neuron-sdk/blob/master/docs/tensorflow-neuron/tutorial-NeuronCore-Group.md\n",
    "        ## For four cores we use \n",
    "        ##     os.environ['NEURONCORE_GROUP_SIZES'] = \"1,1,1,1\" \n",
    "        ## when launching four threads\n",
    "        ## In this logic exists in worker processes, each process should use \n",
    "        ##     os.environ['NEURONCORE_GROUP_SIZES'] = \"1\"\n",
    "        nc_env = ','.join(['1'] * num_neuron_cores)\n",
    "        os.environ['NEURONCORE_GROUP_SIZES'] = nc_env\n",
    "\n",
    "        self.executor = futures.ThreadPoolExecutor(\n",
    "            max_workers=self.num_neuron_cores)\n",
    "\n",
    "    def eval(self):\n",
    "        for m in self.models:\n",
    "            m.eval()\n",
    "\n",
    "    def train(self):\n",
    "        for m in self.models:\n",
    "            m.train()\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        assert all(isinstance(a, torch.Tensor)\n",
    "                   for a in args), \"Non tensor input - tensors are needed to generate batches\"\n",
    "        assert all(a.shape[0] % self.num_neuron_cores ==\n",
    "                   0 for a in args), \"Batch size must be even multiple of the number of parallel neuron cores\"\n",
    "\n",
    "        args_per_core = [[] for i in range(self.num_neuron_cores)]\n",
    "\n",
    "        # Split args\n",
    "        for a in args:\n",
    "            # Based on batch size for arg\n",
    "            step_size = a.shape[0] // self.num_neuron_cores\n",
    "            for i in range(self.num_neuron_cores):\n",
    "                # Append a slice of a view\n",
    "                start = i * step_size\n",
    "                end = (i + 1) * step_size\n",
    "\n",
    "                # Slice\n",
    "                args_per_core[i].append(a[start:end])\n",
    "\n",
    "        # Call each core with their split and wait to complete\n",
    "        running = {self.executor.submit(\n",
    "            self.models[idx], *args_per_core[idx]): idx for idx in range(self.num_neuron_cores)}\n",
    "\n",
    "        results = [None] * self.num_neuron_cores\n",
    "\n",
    "        for future in futures.as_completed(running):\n",
    "            idx = running[future]\n",
    "\n",
    "            results[idx]= future.result()\n",
    "\n",
    "        # Remove zero dimensional tensors (unsqueeze)\n",
    "        # Iterate results per core\n",
    "        for ic in range(len(results)):\n",
    "            # Iterate result tuples\n",
    "            for ir in range(len(results[ic])):\n",
    "                # Unsqueeze if zero dimensional or does not look batched (i.e. first dim does not match batch)\n",
    "                if len(results[ic][ir].size()) == 0 or results[ic][ir].shape[0] != self.batch_size:\n",
    "                    results[ic][ir] = torch.unsqueeze(\n",
    "                        results[ic][ir], 0)\n",
    "\n",
    "        # Concatenate\n",
    "        output = results[0][0]\n",
    "\n",
    "        for i in range(1, len(results)):\n",
    "            for j in range(len(results[i])):\n",
    "                output = torch.cat([output, results[i][j]], 0)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 224, 224])\n",
      "Top 5 labels:\n",
      " ['tiger', 'lynx', 'tiger_cat', 'Egyptian_cat', 'tabby']\n",
      "Completed 400 operations in 0.84 seconds => 474.0 images / second\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import time\n",
    "import torch\n",
    "import torch_neuron\n",
    "import json\n",
    "import numpy as np\n",
    "from urllib import request\n",
    "from torchvision import models, transforms, datasets\n",
    "\n",
    "## Assuming you are working on and inf1.xlarge or inf1.2xlarge\n",
    "num_neuron_cores = 4\n",
    "\n",
    "## Create an image directory containing a small kitten\n",
    "os.makedirs(\"./torch_neuron_test/images\", exist_ok=True)\n",
    "request.urlretrieve(\"https://raw.githubusercontent.com/awslabs/mxnet-model-server/master/docs/images/kitten_small.jpg\",\n",
    "                    \"./torch_neuron_test/images/kitten_small.jpg\")\n",
    "\n",
    "## Fetch labels to output the top classifications\n",
    "request.urlretrieve(\"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\",\"imagenet_class_index.json\")\n",
    "idx2label = []\n",
    "\n",
    "with open(\"imagenet_class_index.json\", \"r\") as read_file:\n",
    "    class_idx = json.load(read_file)\n",
    "    idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]\n",
    "    \n",
    "## Import a sample image and normalize it into a tensor\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "eval_dataset = datasets.ImageFolder(\n",
    "    os.path.dirname(\"./torch_neuron_test/\"),\n",
    "    transforms.Compose([\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "    ])\n",
    ")\n",
    "image, _ = eval_dataset[0]\n",
    "image = torch.tensor(image.numpy()[np.newaxis, ...])\n",
    "\n",
    "## Load model\n",
    "model_neuron = NeuronSimpleDataParallel( 'resnet50_neuron.pt', num_neuron_cores )\n",
    "\n",
    "## Create a \"batch\" image with enough images to go on each of the four cores\n",
    "batch_image = image\n",
    "\n",
    "for i in range(num_neuron_cores - 1):\n",
    "    batch_image = torch.cat( [batch_image, image], 0 )\n",
    "\n",
    "print(batch_image.shape)\n",
    "\n",
    "## Since the first inference also loads the model to the chip let's exclude it \n",
    "## from timing\n",
    "results = model_neuron( batch_image )\n",
    "\n",
    "## Predict\n",
    "loops = 100\n",
    "start = time()\n",
    "for _ in range(loops):\n",
    "    results = model_neuron( batch_image )\n",
    "elapsed_time = time() - start\n",
    "images_sec = loops * batch_image.size(0) / float(elapsed_time)\n",
    "\n",
    "# Get the top 5 results\n",
    "top5_idx = results[0].sort()[1][-5:]\n",
    "\n",
    "# Lookup and print the top 5 labels\n",
    "top5_labels = [idx2label[idx] for idx in top5_idx]\n",
    "print(\"Top 5 labels:\\n {}\".format(top5_labels) )\n",
    "print(\"Completed {} operations in {} seconds => {} images / second\".format(loops * batch_image.size(0), round(elapsed_time,2), round(images_sec,0) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Experiment with different batch sizes:\n",
    "\n",
    "Now that we are using all four cores we can experiment with compiling and running large batch sizes on each of our four cores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.2 Modify the inference code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 labels:\n",
      " ['tiger', 'lynx', 'tiger_cat', 'Egyptian_cat', 'tabby']\n",
      "Completed 2000 operations in 2.92 seconds => 685.0 images / second\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import time\n",
    "import torch\n",
    "import torch_neuron\n",
    "import json\n",
    "import numpy as np\n",
    "from urllib import request\n",
    "from torchvision import models, transforms, datasets\n",
    "\n",
    "## Assuming you are working on and inf1.xlarge or inf1.2xlarge\n",
    "num_neuron_cores = 4\n",
    "batch_size = 5\n",
    "\n",
    "## Create an image directory containing a small kitten\n",
    "os.makedirs(\"./torch_neuron_test/images\", exist_ok=True)\n",
    "request.urlretrieve(\"https://raw.githubusercontent.com/awslabs/mxnet-model-server/master/docs/images/kitten_small.jpg\",\n",
    "                    \"./torch_neuron_test/images/kitten_small.jpg\")\n",
    "\n",
    "## Fetch labels to output the top classifications\n",
    "request.urlretrieve(\"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\",\"imagenet_class_index.json\")\n",
    "idx2label = []\n",
    "\n",
    "with open(\"imagenet_class_index.json\", \"r\") as read_file:\n",
    "    class_idx = json.load(read_file)\n",
    "    idx2label = [class_idx[str(k)][1] for k in range(len(class_idx))]\n",
    "    \n",
    "## Import a sample image and normalize it into a tensor\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225])\n",
    "    \n",
    "eval_dataset = datasets.ImageFolder(\n",
    "    os.path.dirname(\"./torch_neuron_test/\"),\n",
    "    transforms.Compose([\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "    ])\n",
    ")\n",
    "image, _ = eval_dataset[0]\n",
    "image = torch.tensor(image.numpy()[np.newaxis, ...])\n",
    "\n",
    "## Load model\n",
    "model_neuron = NeuronSimpleDataParallel( 'resnet50_neuron_b{}.pt'.format(batch_size), num_neuron_cores, batch_size=batch_size )\n",
    "\n",
    "## Create a \"batch\" image with enough images to go on each of the four cores\n",
    "batch_image = image\n",
    "\n",
    "for i in range((num_neuron_cores * batch_size) - 1):\n",
    "    batch_image = torch.cat( [batch_image, image], 0 )\n",
    "\n",
    "## Since the first inference also loads the model to the chip let's exclude it \n",
    "## from timing\n",
    "results = model_neuron( batch_image )\n",
    "\n",
    "## Predict\n",
    "start = time()\n",
    "loops = 100\n",
    "for _ in range(loops):\n",
    "    results = model_neuron( batch_image )\n",
    "elapsed_time = time() - start\n",
    "images_sec = loops * batch_image.size(0) / elapsed_time\n",
    "\n",
    "# Get the top 5 results\n",
    "top5_idx = results[0].sort()[1][-5:]\n",
    "\n",
    "# Lookup and print the top 5 labels\n",
    "top5_labels = [idx2label[idx] for idx in top5_idx]\n",
    "print(\"Top 5 labels:\\n {}\".format(top5_labels) )\n",
    "print(\"Completed {} operations in {} seconds => {} images / second\".format( \n",
    "    loops * batch_image.size(0), round(elapsed_time, 2), round(images_sec,0) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

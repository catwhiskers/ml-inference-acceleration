{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: apt-get: command not found\n",
      "/usr/bin/sh: apt-get: command not found\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "# !apt-get update\n",
    "# !apt-get install ffmpeg libsm6 libxext6  -y\n",
    "!pip install -q smdebug\n",
    "!pip install -q seaborn\n",
    "!pip install -q plotly\n",
    "!pip install -q opencv-python\n",
    "!pip install -q shap\n",
    "!pip install -q bokeh\n",
    "!pip install -q imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3S0urcTM-uxM"
   },
   "source": [
    "# Using SageMaker Neo to Compile a Tensorflow U-Net Model\n",
    "\n",
    "[SageMaker Neo](https://aws.amazon.com/sagemaker/neo/) makes it easy to compile pre-trained TensorFlow models and build an inference optimized container without the need for any custom model serving or inference code.\n",
    "\n",
    "<img src=\"https://paperswithcode.com/media/methods/Screen_Shot_2020-07-07_at_9.08.00_PM_rpNArED.png\" align=\"center\" style=\"padding: 8px;width:500px;\">\n",
    "\n",
    "[U-Net](https://paperswithcode.com/method/u-net) is an architecture for semantic segmentation. It's a popular model for biological images including Ultrasound, Microscopy, CT, MRI and more. \n",
    "\n",
    "In this example, we will show how deploy a pre-trained U-Net model to a SageMaker Endpoint with Neo compilation using the [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk), and then use the models to perform inference requests. We also provide a performance comparison so you can see the benefits of model compilation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8zMksa4C-uxX"
   },
   "source": [
    "## Setup\n",
    "\n",
    "First, we need to ensure we have SageMaker Python SDK 1.x and Tensorflow 1.15.x. Then, import necessary Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AcGt7hZX-uxY",
    "outputId": "bc1c8c6e-f204-4d04-eef5-4abbf18024d6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -U --quiet --upgrade \"sagemaker\"\n",
    "!pip install -U --quiet \"tensorflow==1.15.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import time\n",
    "from sagemaker.utils import name_from_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWnz80a2-uxZ"
   },
   "source": [
    "Next, we'll get the IAM execution role and a few other SageMaker specific variables from our notebook environment, so that SageMaker can access resources in your AWS account later in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2O3slomA-uxa"
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = Session()\n",
    "region = sess.boto_region_name\n",
    "bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ij91QgHSAH-m"
   },
   "source": [
    "SageMaker [Neo supports Tensorflow 1.15.x](https://docs.amazonaws.cn/en_us/sagemaker/latest/dg/neo-supported-cloud.html). Check your version of Tensorflow to prevent downstream framework errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HTMoVu8M_-M3",
    "outputId": "22fbf21b-254d-45ca-a2c3-b693dc9ef68d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)  # This notebook runs on TensorFlow 1.15.x or earlier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RSxGrG4j-uxa"
   },
   "source": [
    "## Download U-Net Model\n",
    "\n",
    "The SageMaker Neo TensorFlow Serving Container works with any model stored in TensorFlow's [SavedModel format](https://www.tensorflow.org/guide/saved_model). This could be the output of your own training job or a model trained elsewhere. For this example, we will use a pre-trained version of the U-Net model based on this [repo](https://github.com/kamalkraj/DATA-SCIENCE-BOWL-2018)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eqFeogKS-uxa",
    "outputId": "ad9663e6-afb9-4706-a4a7-c2725e483f82"
   },
   "outputs": [],
   "source": [
    "model_name = \"unet_medical\"\n",
    "export_path = \"export\"\n",
    "model_archive_name = \"unet-medical.tar.gz\"\n",
    "model_archive_url = \"https://sagemaker-neo-artifacts.s3.us-east-2.amazonaws.com/{}\".format(\n",
    "    model_archive_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-08 14:59:59--  https://sagemaker-neo-artifacts.s3.us-east-2.amazonaws.com/unet-medical.tar.gz\n",
      "Resolving sagemaker-neo-artifacts.s3.us-east-2.amazonaws.com (sagemaker-neo-artifacts.s3.us-east-2.amazonaws.com)... 52.219.102.66\n",
      "Connecting to sagemaker-neo-artifacts.s3.us-east-2.amazonaws.com (sagemaker-neo-artifacts.s3.us-east-2.amazonaws.com)|52.219.102.66|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7217516 (6.9M) [application/x-gzip]\n",
      "Saving to: ‘unet-medical.tar.gz’\n",
      "\n",
      "100%[======================================>] 7,217,516   16.0MB/s   in 0.4s   \n",
      "\n",
      "2021-11-08 14:59:59 (16.0 MB/s) - ‘unet-medical.tar.gz’ saved [7217516/7217516]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget {model_archive_url}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-trained model and its artifacts are saved in a compressed tar file (.tar.gz) so unzip first with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "._export\n",
      "export/\n",
      "export/._.DS_Store\n",
      "export/.DS_Store\n",
      "export/._Servo\n",
      "export/Servo/\n",
      "export/Servo/._.DS_Store\n",
      "export/Servo/.DS_Store\n",
      "export/Servo/._1\n",
      "export/Servo/1/\n",
      "export/Servo/1/._.DS_Store\n",
      "export/Servo/1/.DS_Store\n",
      "export/Servo/1/._variables\n",
      "export/Servo/1/variables/\n",
      "export/Servo/1/._saved_model.pb\n",
      "export/Servo/1/saved_model.pb\n",
      "export/Servo/1/variables/._variables.data-00000-of-00001\n",
      "export/Servo/1/variables/variables.data-00000-of-00001\n",
      "export/Servo/1/variables/._variables.index\n",
      "export/Servo/1/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf unet-medical.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJETn9oY-uxb"
   },
   "source": [
    "After downloading the model, we can inspect it using TensorFlow's ``saved_model_cli`` command. In the command output, you should see \n",
    "\n",
    "```\n",
    "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
    "\n",
    "signature_def['serving_default']:\n",
    "...\n",
    "```\n",
    "\n",
    "The command output should also show details of the model inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J9wSkL4F-uxb",
    "outputId": "c32a97b9-a312-4edf-ec86-6c8a401867d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\r\n",
      "\r\n",
      "signature_def['serving_default']:\r\n",
      "  The given SavedModel SignatureDef contains the following input(s):\r\n",
      "    inputs['inputs'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 256, 256, 3)\r\n",
      "        name: input_1:0\r\n",
      "  The given SavedModel SignatureDef contains the following output(s):\r\n",
      "    outputs['score'] tensor_info:\r\n",
      "        dtype: DT_FLOAT\r\n",
      "        shape: (-1, 256, 256, 1)\r\n",
      "        name: conv2d_19/Sigmoid:0\r\n",
      "  Method name is: tensorflow/serving/predict\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_path = os.path.join(export_path, \"Servo/1\")\n",
    "!saved_model_cli show --all --dir {model_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5n6jhmSg-uxc"
   },
   "source": [
    "Next we need to create a model archive file containing the exported model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z9kutpTP-uxd"
   },
   "source": [
    "## Upload the model archive file to S3\n",
    "\n",
    "We now have a suitable model archive ready in our notebook. We need to upload it to S3 before we can create a SageMaker Model that. We'll use the SageMaker Python SDK to handle the upload."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TocwZSw4-uxd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model uploaded to: s3://sagemaker-us-west-2-230755935769/model/unet-medical.tar.gz\n"
     ]
    }
   ],
   "source": [
    "model_data = Session().upload_data(path=model_archive_name, key_prefix=\"model\")\n",
    "print(\"model uploaded to: {}\".format(model_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuDTHa9v-uxd"
   },
   "source": [
    "## Create a SageMaker Model and Endpoint\n",
    "\n",
    "Now that the model archive is in S3, we can create an unoptimized Model and deploy it to an \n",
    "Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "J3LQzaj5-uxd"
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "instance_type = \"ml.c4.xlarge\"\n",
    "framework = \"TENSORFLOW\"\n",
    "framework_version = \"1.15.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class sagemaker.tensorflow.serving.Model has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "sm_model = Model(model_data=model_data, framework_version=framework_version, role=role)\n",
    "uncompiled_predictor = sm_model.deploy(initial_instance_count=1, instance_type=instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovafH7uH-uxe"
   },
   "source": [
    "## Make predictions using the endpoint\n",
    "\n",
    "The endpoint is now up and running, and ready to handle inference requests. The `deploy` call above returned a `predictor` object. The `predict` method of this object handles sending requests to the endpoint. It also automatically handles JSON serialization of our input arguments, and JSON deserialization of the prediction results.\n",
    "\n",
    "We'll use this sample image:\n",
    "\n",
    "<img src=\"https://sagemaker-neo-artifacts.s3.us-east-2.amazonaws.com/cell-4.png\" align=\"left\" style=\"padding: 8px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img_fname = \"cell-4.png\"\n",
    "sample_img_url = \"https://sagemaker-neo-artifacts.s3.us-east-2.amazonaws.com/{}\".format(\n",
    "    sample_img_fname\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-11-08 15:03:27--  https://sagemaker-neo-artifacts.s3.us-east-2.amazonaws.com/cell-4.png\n",
      "Resolving sagemaker-neo-artifacts.s3.us-east-2.amazonaws.com (sagemaker-neo-artifacts.s3.us-east-2.amazonaws.com)... 52.219.102.202\n",
      "Connecting to sagemaker-neo-artifacts.s3.us-east-2.amazonaws.com (sagemaker-neo-artifacts.s3.us-east-2.amazonaws.com)|52.219.102.202|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 45936 (45K) [image/png]\n",
      "Saving to: ‘cell-4.png’\n",
      "\n",
      "100%[======================================>] 45,936      --.-K/s   in 0.05s   \n",
      "\n",
      "2021-11-08 15:03:28 (948 KB/s) - ‘cell-4.png’ saved [45936/45936]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget {sample_img_url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "uBkEWKrP-uxe"
   },
   "outputs": [],
   "source": [
    "# read the image file into a tensor (numpy array)\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread(sample_img_fname)\n",
    "original_shape = image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(image, cmap=\"gray\", interpolation=\"none\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.resize(image, (256, 256, 3))\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "image = np.asarray(image)\n",
    "image = np.expand_dims(image, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction took 1.16 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# get a prediction from the endpoint\n",
    "# the image input is automatically converted to a JSON request.\n",
    "# the JSON response from the endpoint is returned as a python dict\n",
    "result = uncompiled_predictor.predict(image)\n",
    "print(\"Prediction took %.2f seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQkAAAD8CAYAAABkQFF6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAArZklEQVR4nO3deVxU9f4/8Nd72GSRTVYVJBfkorkAX7ltlmm5VF8szdKbmpkl5RLJ9eeSWWhczTUrNbd7ye/N8lv6NTOXtLKSMnFJRbNQwB1UFERAYOb9+4NxLgicGYaZOcP4fj4e58Fw5iyvOcCbs30+h5gZQghRH43aAYQQ9k2KhBBCkRQJIYQiKRJCCEVSJIQQiqRICCEUWa1IEFE/IjpBRFlENMVa6xFCWBdZ4z4JInIC8AeARwCcBbAPwFBmPmbxlQkhrMpaexI9AGQx8ylmLgfwKYAEK61LCGFFzlZabisAZ6p9fxZAfH0TBwQEcEREhEUD6HQ6aLXaOt9zcnKCRiOnY8SdZf/+/ZeZObCh81mrSFAd42oc1xDRSwBeAoDw8HBkZGRYbOXXrl3DsmXLsGjRIly6dKnW+5MmTcLAgQPRo0cPuLq6Wmy9AsjJyYGvry9OnjyJLl26IDMzE926dVM7lgBARLnmzGetf6dnAYRV+741gPPVJ2DmFcwcx8xxgYENLm7KKz97FqWlpWjXrl2d7y9YsAAPPPAA3nvvPXz88ccWXfedLiMjA6tWrUK/fv2wZMkSPP7441ixYgUOHjyodjRhJmsViX0AOhDRXUTkCuBZAF9aaV21ODk54bvvvsMvv/yiON3kyZMxadIkG6W6MwwePBiRkZFgZiQnJ4OZcfPmTVRWVqodTZjJKkWCmSsBjAOwHcBxAOuZOdMa66pLcHAwOnXqZKvVidukp6fjxo0bAIDCwkJcu3YN//Vf/6VyKmE2ZlZ9iI2NZUsrKiriQYMGMarOhdQ7aDQafuKJJyy+/jtZXl4eh4WF8f79+zkqKoovX76sdiTBzAAy2Iy/T4c7xZ+bm4thw4Zh1apV2Lhxo9HpdTodLly4YINkd4bS0lIMHz4cZ86cQXx8PFxdXdGiRQu1Y4lGcLgi0aZNGyxfvhw3b95Et27dEBMTA2dna13EEdVduXIFL730Enbs2AEAch7CQThckQCA7Oxs3LhxA0lJSUhKSoKHhweGDh2KPn361Dl9QUGB0ZOcwrjMzEyLXsoW9sEh/8V27doVO3fuxPDhwwEARITw8HDD+wkJCfjtt9+Qk5MDACgvL0dBQYEaUR1CcXExZs+eDQDw8vJSOY2wNIfck7gdM2Pu3LlYt24dAODkyZMoKioCEWHt2rW4fv06/vjjD5VTNl2urq4ICgrC3LlzZU/CATnknoQxR48eNbyeMWMGwsLCMHToUBUTNW3FxcVYvHix2jGElTjsnsTEiRMxevRoo200cnJy8Pvvv+Puu+9GUFAQvv32WxsldBx+fn5YuXKl2jGElThskXB2dkZKSgqio6ONThsVFYVDhw4hPz8fDz/8sA3SOZZr165h7NixascQVuKwRQIAvvjiC5w7d87odEePHsVzzz2HrKwsG6RyPJ6enkhMTFQ7hrAShz4nMX78eLi5uSEpKQklJSWK0xYUFCA/Px/t27e3UTrHMXPmTMyZM6fW+KlTp6J169YqJBIWZc5tmpYerHFbdnUbNmwwent2REQEb9682eRl7t+/n4cMGcJDhgzhkydPcmVlJScmJlrxU9inl19+mYmozm168+ZNteOJaiC3Zddv4cKFRqfJycnBmDFj8NNPP5m0zA4dOuCNN97AjRs30LdvX3Tr1g1btmxpbNQmZ8KECSCq3X3I1q1b4eLiokIiYWl3RJHYvHkz3NzcjE43duxY9OjRw+h0zIzdu3dj/fr18Pb2RlZWFo4ePYozZ87Ax8cHPj4+WLVqFW7evGmJ+HYtOjoaWVlZtQrC008/jYqKCpVSCYsyZ/fD0oO1DzeYmS9evMihoaGKhxz+/v78/fffKy5Hp9Pxrl27jB6+AOCWLVtyfn6+1T+bPTh06BBHRESwj48Ph4SEcEREBJeXl6sdS1QDOdxQFhwcjB07dij2M/HUU08Z7Ydiy5Yt6N27t0nrfP311+Ht7d2gnE1V165dkZ2djfnz5+Orr75Cdna2HG44iDumSABA586dsXLlylp9LoaEhGDSpEnw8fHBlStXFJfx448/mry+5ORkXL161ZyoTdaLL76I2NhYtWMIC7LKczcaKi4ujm15z//evXsxcuRIJCYmws/PDwEBARgwYIBJ85aWlsLDw8PkdV24cAEhISHmRhXCYohoPzPHNXQ+h75Poj7x8fH4v//7P7Rr167Bu8TNmjXD559/jsGDB1spnRD25Y463KguKirKrGNmIkKXLl1Mnv7uu++GTqdr8HqEsBd3bJGwFemnQjR1UiTM4O7ujs6dO6sdQwibkCJhhtatW2PdunWIj6/3yYVCOAwpEmbq3LkznnzySbVjCGF1UiSEEIqkSDTCK6+8YnRvIiMjQ55gLpo0+e1thLS0NPz000+Kz/WIj4+XS6CiSZMi0Qjjxo1Dfn4+unbtWu80Wq3WhomEsDwpEhbwxBNPwNXVVe0YjbZp0yZ56paoRYqEBcycORPvvvtune8xM1JSUmycyDzXrl1DeXk5/v73v2P16tVqxxF24o5su2ENEyZMgJ+fH0aOHFnrvfvvv1+FRA03cuRI6HQ6PPzwwwgKClI7jrATUiQshIgwbNgwaDQaw+MFb41vSt30azQa9O/fX+0Ywo7I4YYFOTs7Y9iwYViwYIFh3KlTp+QSqGjSZE/CwjQaDUJCQgxtOzw9PVVOJETj3JGdzghxJzK305lG7QcTUQ4RHSGiQ0SUoR/nT0TfENGf+q9+jVmHsK3KykrMnDkT//M//6N2FGEnLHG40YuZL1f7fgqAXcw8h4im6L//fxZYj7CByspKpKSkIDg4GDqdDiNGjFA7klCZNc5JJAB4SP86DcD3kCLRZLi5uSEzMxMAEBAQoHIaYQ8aWyQYwA79Y94+YuYVAIKZ+QIAMPMFIpIL7k0IEZn0JHZx52hskbiPmc/rC8E3RPS7qTMS0UsAXgKA8PDwRsYQQlhLo05cMvN5/dd8ABsB9ACQR0ShAKD/ml/PvCuYOY6Z4wIDAxsTQwhhRWYXCSLyJKLmt14DeBTAUQBfArh1b/JIAJsaG1IIoZ7GHG4EA9iof6K0M4BPmHkbEe0DsJ6IRgM4DeDpxscUQqjF7CLBzKcA1OpIgZmvADDtYZlCCLsnjQqEEIqkSAghFEmREEIokiIhhFAkRUIIoUiKhBBCkRQJIYQiKRJCCEVSJIQQiqRICCEUSZEQQiiSIiGEUCRFQgihyCGKRHFxMR544AGEh4dDp9OhuLhY7UhCOIwmXyTy8vLw1FNPYcKECfjyyy/x9ddfo1+/fjh06BCuXr2qdjwhmrwm/wSv9PR0nDhxAkOGDKkxvnv37khLS5Mu4YVopCa/J+Hr6wsPDw+1YwjhsJp8kWjVqhXmzp2LTZs21SgWAwcORK9evVRMJoRjaPKHG5GRkYiMjAQAeHh44MCBAwAAf39/SC/cQjReky8S1Z0+fRru7u5qxxDCoTT5w43qpEAIYXkOVSSEEJYnRUIIoUiKhBBCkRQJIYQiKRJCCEVSJIQQiqRICCEUSZEQQiiSIiGEUCRFQgihSIqEEEKRFAkhhCIpEkIIRUaLBBGtIaJ8IjpabZw/EX1DRH/qv/pVe28qEWUR0Qki6mut4EII2zBlT+JfAPrdNm4KgF3M3AHALv33IKJoAM8C6KSfZykROVksrRDC5owWCWb+AUDBbaMTAKTpX6cBGFht/KfMfJOZswFkAehhmahCCDWYe04imJkvAID+a5B+fCsAZ6pNd1Y/TgjRRFn6xCXVMY7rnJDoJSLKIKKMS5cuWTiGEMJSzC0SeUQUCgD6r/n68WcBhFWbrjWA83UtgJlXMHMcM8dJh7VC2C9zi8SXAEbqX48EsKna+GeJyI2I7gLQAcCvjYsohFCT0d6yiWgdgIcABBDRWQAzAcwBsJ6IRgM4DeBpAGDmTCJaD+AYgEoArzKz1krZhRA2YLRIMPPQet7qXc/07wB4pzGhhBD2Q+64FEIokiIhhFAkRUIIocihHvNnSxcvXsTly5dRVlaG06dPG8YHBQXh/vvvVzGZcTt27MBDDz2Er776qsb4Pn36wNvbW6VUwl5JkTBDQUEBXn/9dZw5cwZFRUU4fPiw4b2IiAgsW7YM/frd3txFXYcPH0ZxcTFycnIwfvx4jB49GvPmzasxTWJiIoKDg+Hv74/x48erlFTYG2Ku84ZIm4qLi+OMjAy1Y5ikvLwcCQkJ2LZtW73TtG/fHsuWLUOfPn1smKx+p06dwrJly9CsWTOsWrUKFy9eVJze09MT/fv3R0JCAp577jkbpRTWRkT7mTmuofPJOYkGuu+++xQLBABkZWXh1KlTNkqkrKioCElJSWjbti2WL19utEAAwI0bN/D5558jKSkJX375pQ1SCnsmhxsN8MADD2D//v1qx2iQ5s2bY+LEiXjsscdQVlbWoHkvX76MZ555Bi4uLsjJyYG/v7+VUgp7JnsSDfDjjz+iU6dOJk2bn5/f4D9KaygqKsLIkSPNzlJWVobr168jOzvbwslEUyFFooH279+PBx980Oh0M2bMgNrnWb777ju4u7vj73//e6OXFR8fj2+//dYCqURTI0WigTQaDeLj402a9pNPPkFxcbGVE9Xv559/RlFRESZOnNjoZWm1WowcOdL4hMLhSJFoICJCixYtTJrW398fTk7q9d43bdo0vPbaa4iIiEBaWhr69++vWhbRdEmRaKDKykqsXbvWpGn79esHd3d3KydSlpSUhPnz5+P999/HwYMHsXjxYuzbtw+urq6q5hJNhxSJBnJzc8Pq1asVpyEiODs7Q6NRf/PGxsYiISEBI0eORF5eHmbMmIF+/frB1dUVFy9eNHwWU7KeP38eTz31lLUjqyYvLw/BwcEICAjAmjVr1I5jN9T/LW6CAgMDFQ85xo0bh/Lyctx77702TFW/48ePIysrC8nJybh+/TquXLmC4uJihIaGYvTo0QCADz/8EB07dgQAhISE1LmcmJgYbNiwwWa5bSU/Px9nz55FRUUFli5diitXrqCkpETtWHZDioQZ7rrrLvzrX/+q8z1fX1906NABRHV196mOu+++G4sXL66VqfrdtomJiThx4gRcXV2xYMECAEBYWBiCg4MRExOD3r17Y9++fTbNbStvvfUWnnvuOTz99NMYPHgwgKob4q5du6ZuMDshN1OZKSIiAomJibXGR0VF2W27h3vuuceQecWKFdBqa3caVl5ejr/97W8AgI4dO+L69ev44IMPEBfX4Lt5m4ylS5cCAAoLCzF16lRkZmZi//79yM/Ph6+vr7rh7IAUiQaqqKjArFmzMGTIEOh0OsP4hQsXwsPDQ8Vkxg0cOBADBw7Em2++adL0RIRRo0bhk08+wZo1awx/TI7Kx8cHS5cuxbFjx6DT6RAZGal2JLsgRcJEb7zxBnbv3g1mxoEDB7BhwwZkZmYa3v/tt9/QunVr/O///q+KKU3z3//933jkkUeQnZ2teO9Dt27d8PLLL+PQoUOq3u9ha9HR0WpHsCvSCrQOt7bJ8ePH8cgjjwCoah5u7NZmJycnDBo0CJ999pnVM1pCZWUl8vPz633fy8tL+pdwIOa2AnXYPYnS0lJoNBqUlpbCx8fH5BOJhYWFiImJQW5uLpi5xiGFMVqtFuvXr4evry/ee+89NGvWzNz4NuHs7IyWLVuqHUPYOYe9urF06VKkpqbivvvuwzfffGPyfEOHDsWpU6eg1WobVCCqW7FiBd5+++07ahddOC6H25O4fv06Pv/8c/z6669Yv349AKB///5YuXIliAhRUVG45557rJ5jzpw5eOyxx+y+KzshjHGoPYnKykrMnj0b6enphgIBADqdDqNHj8YLL7yAsWPHIj09vc75N2/ejOPHj9sqrhAWp9VqMXv2bIsu06GKhEajQWxsLA4ePFjvNIcPH8aYMWPQr18/DBgwoMYhRWRkJAICAiyWJzk5GVevXrXY8oQwRqPRoGfPnhZdpkMdblRWViI5ORlnzpxRnO7YsWM4duwYAKBdu3YAgMGDB8Pf37/GZc3GmjRpklwdEDZFRBYvEg53CXTfvn3o0aNHg+fTaDQgojrvQjQVEaF58+YYPXo0/vGPf8DV1dWubs8Wdza5BIqqW4pHjBhh1rzmXsmoLjg4GHv27EHbtm0bvaz6VFRUGM6bhIWF1WqM5O/vj9atW1tt/eLO41BFwtnZGYmJiRbpiamhnnzySbi6uuKTTz7BG2+8YZV16HQ6fPTRR4a2IS+//DJ27dqFrKwswzR9+vTBiy++aPh+yJAhsjcjGsWhigQzIycnx2LLCw4Oxrhx4wzfL1myBJcuXaoxzaBBg9CtWzckJydb/eYpZsa1a9cwa9YspKen46OPPqo1zc6dO7Fz507D97/99hvCw8MxduxYq2YTjsuhioSTkxNmz54NLy8vzJo1q1HLcnd3x7p169CrVy/DuHvvvRdFRUU1pouLi7PZ7r2Tk5NhL2XRokXYunVrjfejoqLwj3/8o8a44uJijB8/Htu3b8eIESPw5JNP2iSrcBwOd+ISALZu3YoBAwY0ahnNmzevVRDsSUFBAfLy8gAAPXv2xO7du+Hp6Ym9e/eisrISw4YNA1B1iHLixAkAVc8pNbV/TuF4zD1x6ZBFQqvVYu7cuZg+fbrZy7hy5YrdPYymoqICf/3rX/Hzzz/X6KOypKTE0Ey9srISzAwXFxe1Ygo7JVc3qnFyckJISAi8vb3N3hvw9PS0cCrzFBQU4PLly4bv582bh4cfftjQB2N4eHiNfiycnR3yRypUZPQ3iojWAHgcQD4zd9aPewvAGAC3zuJNY+av9e9NBTAagBbABGbeboXcRr3wwgsoLCxESkpKg7sh69Wrl110YgtUnYhMSkrC+fPna4y/1R/l/Pnz0bFjRzRr1swiDyjetm0bKisra4x74IEH4OPj0+hli6bJlH87/wLwAYCPbxu/iJnnVx9BRNEAngXQCUBLADuJKJKZzb9DqRGSkpLg5uaG5ORklJaWmjzfqlWr7GZ3vXXr1ggICKhVJG5JTk4GUHUOZerUqQCARx99FLGxsWat75dffkF5eTmysrIMHei8+uqrmDdvnsUfD1B9HS+88AKCg4Mtuvym5vz580hLS6sxrlmzZkhKSlIpURWjRYKZfyCiCBOXlwDgU2a+CSCbiLIA9ADws/kRG+eVV17BzJkzG1Qk7Im3t7fhMX1arRbPP/88OnfujK5du+Lf//43AOD999/HhAkTMG3aNPTq1QuDBg0ye33Tp0/HqFGjalzq/fDDD5GXl4fQ0FAsWbKkcR+ommbNmiEsLAwA8PbbbxsODTt16mQoeHeKoqIipKamoqKiAitWrDCMd3FxwaVLl5CamqpeOGY2OgCIAHC02vdvAcgBcBjAGgB++vEfAHiu2nSrAQw2tvzY2Fi2psOHD/O2bdsYgEnDyZMnrZrHXDqdjg8cOMB//vkn5+fn84EDB/jAgQNcUVFheH369GmLrGPJkiU1tomTkxMfPnzYQp+kpqlTp7K7u7thXc2bN+du3boZhsuXL1tlvfZCp9Nx165d2cPDg8PDw2v9Prq7u/PUqVMbvR4AGWzC3/vtg7lFIhiAE6pakb4DYI1+/Id1FIlB9SzzJQAZADLCw8MbvQGMOXfuHLu4uLCTk1OdhUGj0fA777zDV69eZa1Wa/U89mLz5s3cokUL9vX1rTF4enrW2ka+vr7cv39/rqystGiGGzducGxsLGdmZtb5s/Hx8WFfX19+9NFHuby83DA4kvo++63BxcWF58+f36h12LRI1PcegKkAplZ7bzuAe4wt39p7EtWtXbuWw8PD2c3NzfADcHV15aSkJJtlsDeLFi1iDw8Pk/e0hg8fzrm5uVxWVmbRHF26dOHw8HAOCgoyKUd6ejqfOXPGohnUoNPpuE2bNkY/b3JyMpeUlJi9HlvvSYRWe52EqvMQQNUJy98AuAG4C8ApAE7Glm/LInFLUlIS9+7dm3v37s2JiYk2X7+9efvtt+vce1AaFi1axLt27bJ4lgMHDhh+Nj4+PooZvLy8eOfOnTWGGzduWDyTtWRkZHBZWRl/8cUXJm3zjRs3mr0uc4uEKZdA1wF4CEAAEZ0FMBPAQ0TUTR88B8DLAMDMmUS0HsAxAJUAXmWVrmwYs3DhQrUj2JW4uDh4e3vjxo0bJs9z66z7okWLEBoaimeeecYiWbp3725of7J48WJkZ2cb3svMzERFRQWys7Nx5swZFBcX17r0O336dAQFBcHPzw/Dhw+3SCZr2bNnD9q3b48dO3aoHaVeDnnHpWi4Xbt2ITs7G+PGjcPNmzcbPH9gYCDeffddPP/88xbPxsyYPHkyxo4di9WrV8PJyQm+vr5ITU1FQUFBvfP5+voaHtsHADNnzrTLZvTMjOeffx4ff3z7XQa1bdy4EQMHDjRrPebecdngXQ9rDGocboi6NW/evEGHHNWHoKAgvvfee/mXX36xeK7t27fz0KFDeeHChRwaGsrR0dG8ZcsW3rNnj2EYPny4Yr6uXbvygw8+aPFslrBlyxaTtnHHjh05JyfHrHXAmuckrD1IkbAfubm5rNFozC4UAHjbtm0Wz6XVannbtm3s6+tryBcQEMDBwcGGYdasWXzu3Dk+d+4ce3h4sEajYSKqla/6POvWrVP9apZOp+OQkBCTtu3q1au5oqLCrPVIkRAWc/LkSfb19TWrQHh5efG3335rtWxarZa1Wi0PGjSoVjEjItZoNKzRaPjkyZN8/vx5Xrt2LQcFBRmG24vGrXkyMzM5Ly+P8/LyuKioyGr5qysqKuLy8nLW6XQcHBxs0vYlIv7999/NWp+5RUJaA4la2rZti6+//hpDhw5Fbm6uyfMFBQXhvffeq9EHh6XdalOTkpKCkpISFBYWori4GIcPH/7Pfz78p4Pjnj17YuPGjQCqnm06cOBAw8nZ8+fPIycnB8yMTp06GdYxcOBAw12ucXFxNVrcWtLy5cvRt29flJeXY9WqVRg6dCi6dOmC7OxsXLhwoc55qn9GW5ETl6Je27dvx+effw4AWLt2rdETmqNGjTK0TrW2Pn364JFHHkGLFi1w+vRpkzoZevPNNw23gbdq1QrOzs545ZVXanT/d7t3330Xfn5+CAgIMPuEoTHJyclYuHAh2rRpg+nTp+Ozzz6Di4sLWrVqhTVr1kCn06Ft27Z4+OGHAQCzZs1CSEhIg9cjJy6FVS1btszornB0dLRVDzWq27BhAy9evLjeO2iNDeHh4TxhwgSOiopiADxr1iyjJ2UnTJhglftCZsyYUWv9AwcO5AkTJrCnpye/9957vHXr1kavB3JOQliTTqfjTz/91Ogf34IFCyy2zgULFhhuqho8eHCd02zatKlRJ1lvDffff79J07Vv396Q6fHHH7fI5/zxxx/55s2b/P7779dan7Ozs2F9a9eubdR6pEgIq6usrOTPPvtM8Y/I19eXv//+e4us78qVK5ybm8uBgYGs0Wg4PDy8xnDmzBnWarUmXz609EBEHB4ezmPHjm30Z718+bLRKxy+vr7cpk0bzsrKMmsdd0yRKCwsZJ1Ox4WFhQ3aQMIyysvLec6cOYq/zE5OTpydnW2xdZaVlXGLFi3Yz8+vRhsTZ2dndnFxYWdnZ1WKRPVi4eLiwmvXruWCgoJGbduVK1fWWrafnx+PGjWq0Q3bzC0STerqxqlTp9CrVy/885//xJgxYwwn1QDgL3/5i9W7tBdAeno6pkyZojiNVqut+g9kIW5uboYu/DZu3IiUlBScPHkS169ft9g6zNWsWTOEhISgrKwM48aNw/Dhw/Hjjz/C09MT3t7ehqsspnBxcUFQUBC6detmGOft7Y3du3dbIbnp7P7qxtWrV7Ft2zYAVWeaDx06VOd0c+bMweuvv243PUo5qt27d+Ohhx4yOt2pU6dw1113WS1Hamoqjh49ivLycnzxxRdWW48xrVu3RlJSEiIiInD69Gn8+uuvhve6d+9uuJRqDxzy6kZJSQmPGjXK5N2+yZMnm70rJkyTm5vLCQkJRn8WiYmJFu93oi6lpaWcmprKqamp/OCDDxrNNX36dIsfbnTs2JF37txp9c/aWDDzcMOu9ySeeOIJfPXVVyYvx83NDWVlZZaMJm5z9OhRDB06FEePHq13mrfeegsxMTF47LHHbNqh8O+//44///wTAFBaWlpnq9S+ffti+/bt6NatG7p37w5vb29s3boV06ZNw6hRo8w+TOrYsSMiIyMBAOvXr7fLQ1+H2pMYMWIER0ZGNriiu7m5WabkinqVlJTwzJkz6/0ZTJkyxS76c9DpdHzixAk+ceIET5w4sVZODw8PDgwM5ODgYN68eTPHx8fzDz/8YJE9i/bt23NkZCSPGTNG7c1QAxzh6sbHH3/MK1eu5GvXrnF+fj7/8ccfrNFo2NPTk11cXEwqEvbwC+qIKisrOSgoiP39/ev9WTg7O7Ofn5/NbqgyVUVFBZeUlBiG48ePs6enJ3t6erKzszO7ubnxkSNHuHPnzpyfn89Xr17lCRMm8I4dO7h9+/bs6elZow9OUweNRsPu7u68Zs0avn79Ol+/fl3V7eAQReLq1atcUFDAvXr1Mmzo6OhoPnbsGI8ePZrDwsI4KiqqzpZ9t4a2bdtafOOK//j+++/r3fajRo1SO16DTZ06laOiorhz58588eJFjoqK4rfffpsvXLhQ4x/OkSNHOCoqiqOiohrcg9etwcnJiTMzMzk3N1eVz2pukbCrS6D79u1DRkZGje7cjx07hujoaABVPQ7Fxsbi2WefhZubG6Kjo7F3717DtBqNBo8++qjNc99JWrRoUe9Dh2NiYmycpvFSU1NrdFd//PhxAMDKlStxzz33oHPnzti6dSv69+9veG/27Nk4cOAAKisrsXnzZpPXpdVq0alTJ3Tu3BkpKSkAqhqg2fvzWe3qxOXBgwexadMmpKWlIScnR3GewMBA9OnTB+vWrcOTTz6JPXv2oLCwUE5cCot79913MXny5Frjy8vLFRuWZWVlIScnB8XFxTh69Cg0Gg2mTZtWY5oxY8YgPDzc4pnr4hDPAvXx8UF5eTlKSkqMTnvp0iWsW7cOAHDhwgWzulwTwhR1FQgAcHV1VSwSFy5cwKVLl1BaWoqcnBxoNBo8/fTT1oppNXZVJA4ePAh/f39EREQgPz/f5Pl++eUXAAARYcCAAfj666+tFVEIk4WGhiI0NBQAEB8fr3Ia89lNkfj111+xa9cuODk5Yf/+/Q2ePz09HdHR0XbzoF8hHIXd/EV17doVrVu3xgcffACttuG98Ht5ecHHxwfNmze3Qrq63eoV6fz589DpdDZbrxC2ZDd7Evv27cP06dPNmrdLly42KQ4//fQT4uPjsXfvXkRFRWHy5MkIDAzEhg0bMGfOHDRv3hz+/v6Ii2v4TW1C2Cu7KRLmio+Px0cffYSIiAirrys9PR179+5FXl4e0tLS8M9//tPw3q3nO7Rv3x4rV640qRGUEE2B3RxuREZGNvjBLjExMVi+fDm6du1qnVC3mTx5MoKCgpCVlYVVq1bVOU1WVhYSExPx/PPPG9oRCNGU2U2RuHjxIvz8/DBkyBCj07q7u2Pv3r349NNPa7S9t4W//e1vGDZsmOI0v//+O9LS0pCXl2ejVEJYj90cbkRHR6NDhw4ICwvDuXPnsGfPnhrvExE0Gg327NmDdu3aISAgwOYZdTodIiMjUVRUBI1GY/Rk5RNPPIFjx44ZLoMJ0RTZzZ6Es7MzEhMTUVBQgOzsbLRs2RItW7ZEYGAg3N3dsWTJElRUVCA+Pl6VAgFUdeN+8OBBHDhwAGvWrIGXlxdatmxZb0c3165dQ1hYGM6ePWvoWUmIJsecBh+WHpT6uDxx4gSnpKQ0olmLZZWVlXFcXBwD4KFDh/IPP/zAHTt2ZCLiHj161Nu4569//ava0cUdDmY28LKbPYn6REZGYsaMGWrHMHBzc8OWLVvQv39/rFu3Dj179sSJEyeg0WiQkJCAVq1aYezYsYiKiqox38WLF7F8+XIcOXJEpeRCmMfui4Q9IiJ06dIFCQkJhnFarRbTp08HEcHJyclw5+c777wDIkJOTg7S0tKq2ucL0YRIkTCDl5cX2rZtW+dewdmzZ/Hhhx/i2LFjAIAtW7aAmREdHY0hQ4Zg4sSJZt12LoRapEiYwd3dHSNGjMAzzzwDIgIR1Ttteno6gKr7J2bNmoXvv/8eBQUFskchmgy76k+iqWFmaLVaFBYWol27digsLDRpPj8/P7i5ueH06dPyCABhM+b2J2F0T4KIwojoOyI6TkSZRDRRP96fiL4hoj/1X/2qzTOViLKI6AQR9W1oqKaCiODs7IykpCQUFxebPF9KSgpyc3OlQIgmwZTDjUoAk5j5LwD+CuBVIooGMAXALmbuAGCX/nvo33sWQCcA/QAsJSIna4S3Fx9//DFefPFFk6cfP348PvjgA2k5KpoEo0WCmS8w8wH96+sAjgNoBSABQJp+sjQAA/WvEwB8ysw3mTkbQBaAHhbObXeWLl2KqVOnmjy93FwlmooGnbgkoggA3QHsBRDMzBeAqkICIEg/WSsAZ6rNdlY/zqFpNBq8+eabNTpVrU9qaipmzJghHeSIJsHk31Ii8gLwBYDXmLlIadI6xtU6O0pELxFRBhFlVO8duylr1qwZXnvtNWRlZSErKwuxsbE13h88eDCysrLw2muvwd3dXaWUQjSMSQ28iMgFVQXi38y8QT86j4hCmfkCEYUCuNUp5VkAYdVmbw3g/O3LZOYVAFYAVVc3zMxvd9zd3Q1Pkk5PT69x3sHJyUlOVoomx5SrGwRgNYDjzLyw2ltfAhipfz0SwKZq458lIjciugtABwC/4g7k6uqKZs2aGQYpEKIpMmVP4j4AwwEcIaJD+nHTAMwBsJ6IRgM4DeBpAGDmTCJaD+AYqq6MvMrMDe+0UghhF4wWCWb+CXWfZwCA3vXM8w6AdxqRSwhhJ+T0uhBCkRQJIYQiKRJCCEVSJIQQiqRICCEUSZEQQiiSIiGEUCRFQgihSIqEEEKRFAkhhCIpEkIIRVIkhBCKpEgIIRRJkRBCKJIiIYRQZFL3dUI0FYWFhbh582aNcR4eHvDy8lIpUdMnexLCocyePRtt2rRBcHCwYZg7d67asZo02ZMQDmXevHlwcXHBxYsXDeNiYmJUTNT0SZEQTd7Zs2excOFCPPbYY+jdu7dJzz4RppPDDdHk+fj4oF+/fmjbti3eeust9O3bF+Xl5WrHchjyVHHhUPLz81FSUoI2bdrg1KlTmDdvHpYvX652LLtg7lPFpUgIh8XM0Gq1cHaWo2rA/CIhhxvCYRGRFAgLkCIhhFAkRUIIoUiKhBBCkRQJIYQiKRJCCEVSJIQQiqRICCEUSZEQQiiSIiGEUCRFQgihSIqEEEKR0SJBRGFE9B0RHSeiTCKaqB//FhGdI6JD+mFAtXmmElEWEZ0gor7W/ABCCOsypfVLJYBJzHyAiJoD2E9E3+jfW8TM86tPTETRAJ4F0AlASwA7iSiSmbWWDC6EsA2jexLMfIGZD+hfXwdwHEArhVkSAHzKzDeZORtAFoAelggrhLC9Bp2TIKIIAN0B7NWPGkdEh4loDRH56ce1AnCm2mxnoVxUhBB2zOQiQUReAL4A8BozFwFYBqAdgG4ALgBYcGvSOmav1bMNEb1ERBlElHHp0qWG5hZC2IhJRYKIXFBVIP7NzBsAgJnzmFnLzDoAK/GfQ4qzAMKqzd4awPnbl8nMK5g5jpnjAgMDG/MZhBBWZLT7OiIiAGkACpj5tWrjQ5n5gv51EoB4Zn6WiDoB+ARVRaMlgF0AOiiduCSiSwBuALjcuI9jMwGQrNYgWa3jVtY2zNzg/8imXN24D8BwAEeI6JB+3DQAQ4moG6oOJXIAvAwAzJxJROsBHEPVlZFXjV3ZYOZAIsowp/89NUhW65Cs1tHYrEaLBDP/hLrPM3ytMM87AN4xN5QQwn7IHZdCCEX2VCRWqB2gASSrdUhW62hUVrt47oYQwn7Z056EEMIOqV4kiKifviFYFhFNUTvP7Ygoh4iO6BuxZejH+RPRN0T0p/6rn7HlWCnbGiLKJ6Kj1cbVm03Nhnf1ZLXLRoIKjRrtbtvapAEmM6s2AHACcBJAWwCuAH4DEK1mpjoy5gAIuG3cuwCm6F9PATBXpWw9AcQAOGosG4Bo/fZ1A3CXfrs7qZz1LQDJdUyrdtZQADH6180B/KHPZHfbViGrxbat2nsSPQBkMfMpZi4H8CmqGojZuwRU3WAG/deBaoRg5h8AFNw2ur5sqja8qydrfdTOWl+jRrvbtgpZ69PgrGoXiabQGIwB7CCi/UT0kn5cMOvvNtV/DVItXW31ZbPXbW3XjQRva9Ro19vWWg0w1S4SJjUGU9l9zBwDoD+AV4mop9qBzGSP27pRjQStrY5GjfVOWsc4m+a1dAPM6tQuEiY1BlMTM5/Xf80HsBFVu2Z5RBQKVLVhAZCvXsJa6stmd9uaG9lI0JrqatQIO9221miAWZ3aRWIfgA5EdBcRuaKqR6svVc5kQESe+t64QESeAB4FcBRVGUfqJxsJYJM6CetUX7YvATxLRG5EdBeADgB+VSGfwa0/OL0nUbVtAZWz6hs1rgZwnJkXVnvL7rZtfVktum1tdcZY4ezsAFSdkT0JYLraeW7L1hZVZ4J/A5B5Kx+AFqhq3fqn/qu/SvnWoWpXsgJV/yFGK2UDMF2/nU8A6G8HWdcCOALgsP6XN9ROst6Pql3wwwAO6YcB9rhtFbJabNvKHZdCCEVqH24IIeycFAkhhCIpEkIIRVIkhBCKpEgIIRRJkRBCKJIiIYRQJEVCCKHo/wM+06bYiu+m3wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the predicted segmentation image\n",
    "\n",
    "cutoff = 0.4\n",
    "segmentation_img = np.squeeze(np.asarray(result[\"predictions\"])) > cutoff\n",
    "segmentation_img = segmentation_img.astype(np.uint8)\n",
    "segmentation_img = np.resize(segmentation_img, (original_shape[0], original_shape[1]))\n",
    "plt.imshow(segmentation_img, \"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncompiled Predictor Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions for un-compiled model: \n",
      "\n",
      "\n",
      "P95: 538.2373929023742 ms\n",
      "\n",
      "P90: 505.3648710250855 ms\n",
      "\n",
      "P50: 397.51875400543213 ms\n",
      "\n",
      "Average: 413.6315083503723 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shape_input = np.random.rand(1, 256, 256, 3)\n",
    "uncompiled_results = []\n",
    "\n",
    "for _ in range(100):\n",
    "    start = time.time()\n",
    "    uncompiled_predictor.predict(image)\n",
    "    uncompiled_results.append((time.time() - start) * 1000)\n",
    "\n",
    "print(\"\\nPredictions for un-compiled model: \\n\")\n",
    "print(\"\\nP95: \" + str(np.percentile(uncompiled_results, 95)) + \" ms\\n\")\n",
    "print(\"P90: \" + str(np.percentile(uncompiled_results, 90)) + \" ms\\n\")\n",
    "print(\"P50: \" + str(np.percentile(uncompiled_results, 50)) + \" ms\\n\")\n",
    "print(\"Average: \" + str(np.average(uncompiled_results)) + \" ms\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile model using SageMaker Neo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the value of data_shape below and\n",
    "# specify the name & shape of the expected inputs for your trained model in JSON\n",
    "# Note that -1 is replaced with 1 for the batch size placeholder\n",
    "data_shape = {\"inputs\": [1, 224, 224, 3]}\n",
    "\n",
    "instance_family = \"ml_c4\"\n",
    "\n",
    "compilation_job_name = name_from_base(\"medical-tf-Neo\")\n",
    "# output path for compiled model artifact\n",
    "compiled_model_path = \"s3://{}/{}/output\".format(bucket, compilation_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "?????????????????????????.................................................!"
     ]
    }
   ],
   "source": [
    "optimized_estimator = sm_model.compile(\n",
    "    target_instance_family=instance_family,\n",
    "    input_shape=data_shape,\n",
    "    job_name=compilation_job_name,\n",
    "    role=role,\n",
    "    framework=framework.lower(),\n",
    "    framework_version=framework_version,\n",
    "    output_path=compiled_model_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Optimized Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "optimized_predictor = optimized_estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=instance_type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction took 0.81 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# get a prediction from the endpoint\n",
    "# the image input is automatically converted to a JSON request.\n",
    "# the JSON response from the endpoint is returned as a python dict\n",
    "result = optimized_predictor.predict(image)\n",
    "print(\"Prediction took %.2f seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiled Predictor Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions for compiled model: \n",
      "\n",
      "\n",
      "P95: 394.85707283020014 ms\n",
      "\n",
      "P90: 373.90453815460205 ms\n",
      "\n",
      "P50: 341.60518646240234 ms\n",
      "\n",
      "Average: 337.3559617996216 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compiled_results = []\n",
    "test_input = {\"instances\": np.asarray(shape_input).tolist()}\n",
    "# Warmup inference.\n",
    "optimized_predictor.predict(image)\n",
    "# Inferencing 100 times.\n",
    "for _ in range(100):\n",
    "    start = time.time()\n",
    "    optimized_predictor.predict(image)\n",
    "    compiled_results.append((time.time() - start) * 1000)\n",
    "\n",
    "print(\"\\nPredictions for compiled model: \\n\")\n",
    "print(\"\\nP95: \" + str(np.percentile(compiled_results, 95)) + \" ms\\n\")\n",
    "print(\"P90: \" + str(np.percentile(compiled_results, 90)) + \" ms\\n\")\n",
    "print(\"P50: \" + str(np.percentile(compiled_results, 50)) + \" ms\\n\")\n",
    "print(\"Average: \" + str(np.average(compiled_results)) + \" ms\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we compare inference speed up provided by SageMaker Neo. P90 is 90th percentile latency. We add this because it represents the tail of the latency distribution (worst case). More information on latency percentiles [here](https://blog.bramp.net/post/2018/01/16/measuring-percentile-latency/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P90 Speedup: 1.35\n",
      "P50 Speedup: 1.16\n",
      "Average Speedup: 1.23\n"
     ]
    }
   ],
   "source": [
    "p90 = np.percentile(uncompiled_results, 90) / np.percentile(compiled_results, 90)\n",
    "p50 = np.percentile(uncompiled_results, 50) / np.percentile(compiled_results, 50)\n",
    "avg = np.average(uncompiled_results) / np.average(compiled_results)\n",
    "\n",
    "print(\"P90 Speedup: %.2f\" % p90)\n",
    "print(\"P50 Speedup: %.2f\" % p50)\n",
    "print(\"Average Speedup: %.2f\" % avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Elastic Inference Endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update_endpoint is a no-op in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "predictor_ei = sm_model.deploy(initial_instance_count=1, \n",
    "                        instance_type='ml.c4.xlarge',\n",
    "                            accelerator_type='ml.eia2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction took 1.07 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# get a prediction from the endpoint\n",
    "# the image input is automatically converted to a JSON request.\n",
    "# the JSON response from the endpoint is returned as a python dict\n",
    "result = predictor_ei.predict(image)\n",
    "print(\"Prediction took %.2f seconds\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions for compiled model: \n",
      "\n",
      "\n",
      "P95: 373.9136576652527 ms\n",
      "\n",
      "P90: 359.7217321395874 ms\n",
      "\n",
      "P50: 335.57236194610596 ms\n",
      "\n",
      "Average: 328.0187797546387 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ei_results = []\n",
    "test_input = {\"instances\": np.asarray(shape_input).tolist()}\n",
    "# Warmup inference.\n",
    "optimized_predictor.predict(image)\n",
    "# Inferencing 100 times.\n",
    "for _ in range(100):\n",
    "    start = time.time()\n",
    "    predictor_ei.predict(image)\n",
    "    ei_results.append((time.time() - start) * 1000)\n",
    "\n",
    "print(\"\\nPredictions for compiled model: \\n\")\n",
    "print(\"\\nP95: \" + str(np.percentile(ei_results, 95)) + \" ms\\n\")\n",
    "print(\"P90: \" + str(np.percentile(ei_results, 90)) + \" ms\\n\")\n",
    "print(\"P50: \" + str(np.percentile(ei_results, 50)) + \" ms\\n\")\n",
    "print(\"Average: \" + str(np.average(ei_results)) + \" ms\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Comparison "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can compare with increased performance between the vanilla predictor and the one equipped with elastic inference. The design decision could reference to the usage pattern and the price structure of [elastic inference](https://aws.amazon.com/machine-learning/elastic-inference/pricing/). Or plot a graph like what in this [blog](https://aws.amazon.com/blogs/machine-learning/increasing-performance-and-reducing-the-cost-of-mxnet-inference-using-amazon-sagemaker-neo-and-amazon-elastic-inference/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P90 Speedup: 1.36\n",
      "P50 Speedup: 1.14\n",
      "Average Speedup: 1.23\n"
     ]
    }
   ],
   "source": [
    "p90 = np.percentile(uncompiled_results, 90) / np.percentile(ei_results, 90)\n",
    "p50 = np.percentile(uncompiled_results, 50) / np.percentile(ei_results, 50)\n",
    "avg = np.average(uncompiled_results) / np.average(ei_results)\n",
    "\n",
    "print(\"P90 Speedup: %.2f\" % p90)\n",
    "print(\"P50 Speedup: %.2f\" % p50)\n",
    "print(\"Average Speedup: %.2f\" % avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WK615wgU-uxg"
   },
   "source": [
    "## Additional Information\n",
    "\n",
    "## Cleaning up\n",
    "\n",
    "To avoid incurring charges to your AWS account for the resources used in this tutorial, you need to delete the SageMaker Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTSKcyHW-uxg"
   },
   "outputs": [],
   "source": [
    "uncompiled_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "sagemaker-neo-tf-hub-example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
